{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Understanding Data Roles in Tech","text":""},{"location":"#learn-by-doing-experience-20-data-career-paths-through-hands-on-projects","title":"Learn by Doing: Experience 20 Data Career Paths Through Hands-On Projects","text":"<ul> <li> <p> Get Started in 5 Minutes</p> <p>Set up your development environment and start building your first data project</p> <p> Quick Start</p> </li> <li> <p> Build Real Projects</p> <p>Create an end-to-end data system: pipelines, dashboards, ML models, and more</p> <p> View Projects</p> </li> <li> <p> Explore 20 Roles</p> <p>Deep dive into what Data Engineers, Data Scientists, ML Engineers, and 17 other roles actually do</p> <p> Browse Roles</p> </li> <li> <p> Find Your Path</p> <p>Discover which data career aligns with your interests through self-assessment</p> <p> Career Paths</p> </li> </ul>"},{"location":"#why-this-guide","title":"Why This Guide?","text":"<p>Confused About Data Careers?</p> <p>\"I want to work with data, but which role is right for me?\"</p> <p>\"What's the difference between a Data Engineer and Data Scientist?\"</p> <p>\"What do these people actually DO all day?\"</p> <p>If you've asked these questions, you're not alone. The data industry has exploded with new roles, and the boundaries between them are blurry. Every company defines these roles differently.</p> <p>This guide solves that problem.</p>"},{"location":"#how-this-guide-works","title":"How This Guide Works","text":""},{"location":"#learn-the-fundamentals","title":"Learn the Fundamentals","text":"<p>Start by understanding what data really means in tech. We'll trace a simple book purchase through an entire data system, showing you the 7 stages of the data lifecycle and the undercurrents that make everything work.</p> <p>Start Learning \u2192</p>"},{"location":"#build-real-projects","title":"Build Real Projects","text":"<p>Don't just read about data roles\u2014experience them. You'll build a complete e-commerce analytics platform called \"BookStore Analytics\":</p> <ul> <li>Data pipelines in Apache Airflow (Data Engineer)</li> <li>Clean data models with dbt (Analytics Engineer)  </li> <li>SQL analysis answering business questions (Data Analyst)</li> <li>Interactive dashboards in Looker Studio (BI Engineer)</li> <li>ML models for recommendations and churn prediction (Data Scientist)</li> <li>Production APIs deploying models (ML Engineer)</li> <li>Monitoring systems ensuring quality (MLOps Engineer)</li> </ul> <p>...and more across all 20 roles.</p> <p>View the Project \u2192</p>"},{"location":"#discover-your-role","title":"Discover Your Role","text":"<p>Through hands-on exercises, you'll discover which work resonates with you. Do you love transforming messy data? Building dashboards? Training ML models? You'll know by the end.</p> <p>Take the Assessment \u2192</p>"},{"location":"#what-youll-build","title":"What You'll Build","text":"<p>By the end of this guide, you'll have created:</p> <pre><code>graph TB\n    A[Raw Data&lt;br/&gt;CSV Files &amp; APIs] --&gt; B[Data Pipeline&lt;br/&gt;Apache Airflow]\n    B --&gt; C[Data Warehouse&lt;br/&gt;Snowflake]\n    C --&gt; D[Clean Tables&lt;br/&gt;dbt Models]\n    D --&gt; E[SQL Analysis&lt;br/&gt;Business Insights]\n    D --&gt; F[Dashboard&lt;br/&gt;Looker Studio]\n    D --&gt; G[ML Models&lt;br/&gt;Python/scikit-learn]\n    G --&gt; H[Production API&lt;br/&gt;Flask/FastAPI]\n    H --&gt; I[Monitoring&lt;br/&gt;Quality &amp; Performance]\n\n    style A fill:#e1f5ff\n    style B fill:#fff9e6\n    style C fill:#f0e6ff\n    style D fill:#e6ffe6\n    style E fill:#ffe6e6\n    style F fill:#ffe6e6\n    style G fill:#fff0e6\n    style H fill:#fff0e6\n    style I fill:#e6f3ff</code></pre> <p>A complete, portfolio-ready data system that demonstrates skills across the entire data lifecycle.</p>"},{"location":"#the-20-roles-youll-experience","title":"The 20 Roles You'll Experience","text":""},{"location":"#infrastructure--platform-4-roles","title":"Infrastructure &amp; Platform (4 roles)","text":"<p>Build the foundation that data systems run on</p> <ul> <li>Backend Engineer</li> <li>Database Administrator</li> <li>Platform Engineer</li> <li>DevOps Engineer</li> </ul>"},{"location":"#data-pipeline-3-roles","title":"Data Pipeline (3 roles)","text":"<p>Move and transform data at scale</p> <ul> <li>Data Engineer</li> <li>Analytics Engineer</li> <li>DataOps Engineer</li> </ul>"},{"location":"#analysis--intelligence-4-roles","title":"Analysis &amp; Intelligence (4 roles)","text":"<p>Extract insights and build predictions</p> <ul> <li>Data Analyst</li> <li>BI Engineer</li> <li>Data Scientist</li> <li>ML Scientist/Researcher</li> </ul>"},{"location":"#production-3-roles","title":"Production (3 roles)","text":"<p>Deploy and scale data products</p> <ul> <li>ML Engineer</li> <li>AI Engineer</li> <li>MLOps Engineer</li> </ul>"},{"location":"#support--quality-3-roles","title":"Support &amp; Quality (3 roles)","text":"<p>Ensure reliability and governance</p> <ul> <li>QA Engineer</li> <li>Data Governance Specialist</li> <li>Frontend Engineer</li> </ul>"},{"location":"#strategic-3-roles","title":"Strategic (3 roles)","text":"<p>Design systems and lead teams</p> <ul> <li>Data Architect</li> <li>Data Product Manager</li> <li>Engineering Manager</li> </ul>"},{"location":"#who-this-guide-is-for","title":"Who This Guide Is For","text":"<p>Perfect If You're...</p> <ul> <li>Career changer exploring data roles</li> <li>Recent graduate choosing a specialization</li> <li>Professional wanting to understand adjacent roles</li> <li>Manager building a data team</li> <li>Developer transitioning into data</li> <li>Analyst considering Data Engineering or Data Science</li> </ul> <p>Prerequisites</p> <p>None! This guide assumes no prior coding experience. We'll teach you everything you need as we go.</p> <p>All you need is:</p> <ul> <li>\u2705 Curiosity about data</li> <li>\u2705 Willingness to try new things</li> <li>\u2705 ~10 hours to work through the content</li> <li>\u2705 A computer (Windows, Mac, or Linux)</li> </ul>"},{"location":"#what-makes-this-different","title":"What Makes This Different","text":"Other Resources This Guide Watch tutorials Build real projects Read about roles Experience the work Theory-heavy Hands-on focused Single role focus All 20 roles Unclear next steps Personalized roadmap"},{"location":"#ready-to-start","title":"Ready to Start?","text":"<ul> <li> <p> New to Data?</p> <p>Start with the fundamentals to understand what data means in tech</p> <p> Learn the Basics</p> </li> <li> <p> Ready to Build?</p> <p>Jump straight into hands-on projects</p> <p> Start Building</p> </li> <li> <p> Know What You Want?</p> <p>Browse specific roles you're interested in</p> <p> Explore Roles</p> </li> </ul>"},{"location":"#about-the-author","title":"About the Author","text":"<p>Gemma Down has spent 12 years working across the data stack in roles including:</p> <ul> <li>Data Analyst</li> <li>Data Scientist</li> <li>Analytics Engineer</li> <li>Data Engineer</li> <li>Full Stack Engineer</li> </ul> <p>She has also recruited for Data Analysts, Data Engineers, Analytics Engineers, and Engineering Managers, giving her insight into what these roles really require\u2014from both sides of the hiring table.</p> <p>This guide distills 12 years of experience into a practical resource for anyone exploring data careers.</p> <p> GitHub  LinkedIn</p>"},{"location":"#contributing","title":"Contributing","text":"<p>This guide is open source! Found a typo? Have a suggestion? Want to add a role?</p> <p> Open an Issue  Submit a PR</p> <p>Stay Updated</p> <p>This guide is actively maintained. Star the GitHub repo to get notified of updates.</p>"},{"location":"career-paths/","title":"Career Paths","text":"<p>Find your path in data:</p> <ul> <li>Self-Assessment</li> <li>Learning Roadmaps</li> <li>Job Search Strategy</li> <li>Resources</li> </ul>"},{"location":"career-paths/job-search/","title":"Job Search Strategy","text":"<p>Content coming soon...</p>"},{"location":"career-paths/learning-roadmaps/","title":"Learning Roadmaps","text":"<p>Content coming soon...</p>"},{"location":"career-paths/resources/","title":"Resources","text":"<p>Content coming soon...</p>"},{"location":"career-paths/self-assessment/","title":"Self-Assessment","text":"<p>Content coming soon...</p>"},{"location":"fundamentals/","title":"Fundamentals","text":"<p>Learn the basics of data in tech.</p> <ul> <li>What is Data?</li> <li>The Data Lifecycle</li> <li>Modern Data Stack</li> <li>The Project</li> </ul>"},{"location":"fundamentals/data-lifecycle/","title":"The Data Lifecycle","text":"<p>Content coming soon...</p>"},{"location":"fundamentals/modern-data-stack/","title":"Modern Data Stack","text":"<p>Content coming soon...</p>"},{"location":"fundamentals/the-project/","title":"The Project: BookStore Analytics","text":"<p>Content coming soon...</p>"},{"location":"fundamentals/what-is-data/","title":"What is Data in Tech?","text":"<p>Learning Objectives</p> <p>By the end of this lesson, you'll be able to:</p> <ul> <li>Trace how a single user action generates data across systems</li> <li>Identify the 7 stages of the data lifecycle</li> <li>Recognize which roles work at each stage</li> </ul>"},{"location":"fundamentals/what-is-data/#the-30-second-book-purchase","title":"The 30-Second Book Purchase","text":"<p>Let's follow a simple online book purchase and see what happens behind the scenes.</p>"},{"location":"fundamentals/what-is-data/#user-experience","title":"User Experience","text":"<pre><code>14:32:15 - Search \"Python programming\"\n14:32:18 - Click on \"Python Crash Course\"\n14:32:25 - Add to cart\n14:32:40 - Enter payment info\n14:32:45 - Complete purchase\n14:32:46 - Order confirmed\n</code></pre> <p>Simple, right? But behind those 30 seconds, hundreds of data processes happened.</p>"},{"location":"fundamentals/what-is-data/#stage-1-data-generation","title":"Stage 1: Data Generation","text":"<p>The millisecond you typed \"Python programming,\" data was generated: <pre><code>{\n  \"event\": \"search\",\n  \"user_id\": \"user_12345\",\n  \"session_id\": \"sess_abc789\",\n  \"search_term\": \"Python programming\",\n  \"timestamp\": \"2024-11-07T14:32:15.234Z\",\n  \"device\": \"Chrome/MacOS\",\n  \"page_url\": \"/books\"\n}\n</code></pre></p> <p>Who Does This?</p> <p>Backend Engineers build the APIs that capture every user action.</p>"},{"location":"fundamentals/what-is-data/#why-it-matters","title":"Why It Matters","text":"<p>Without accurate data capture, everything downstream fails. This is the foundation of all data work.</p>"},{"location":"fundamentals/what-is-data/#stage-2-data-collection--storage","title":"Stage 2: Data Collection &amp; Storage","text":"<p>Now we have events. Where do they go? <pre><code>graph LR\n    A[User Action] --&gt; B[API]\n    B --&gt; C[Message Queue&lt;br/&gt;Kafka]\n    C --&gt; D[Transactional DB&lt;br/&gt;PostgreSQL]\n    C --&gt; E[Data Warehouse&lt;br/&gt;Snowflake]\n    C --&gt; F[Data Lake&lt;br/&gt;S3]</code></pre></p> Transactional DatabaseData WarehouseData Lake <p>Purpose: Live application data</p> <ul> <li>Fast reads/writes</li> <li>ACID compliant</li> <li>Powers the app</li> </ul> <p>Who manages: Database Administrators, Backend Engineers</p> <p>Purpose: Historical analysis</p> <ul> <li>P for queries</li> <li>Stores years of data</li> <li>Analytics-friendly</li> </ul> <p>Who manages: Data Engineers, Analytics Engineers</p> <p>Purpose: Raw, unstructured data</p> <ul> <li>Images, logs, clickstreams</li> <li>Cheap storage</li> <li>Flexible format</li> </ul> <p>Who manages: Data Engineers, Platform Engineers</p>"},{"location":"fundamentals/what-is-data/#stage-3-data-transformation","title":"Stage 3: Data Transformation","text":"<p>Raw data is messy. Here's what we need to fix:</p> Common Data Quality Issues <ul> <li>Duplicate records</li> <li>Missing values</li> <li>Inconsistent formats</li> <li>Different time zones</li> <li>Typos and errors</li> </ul>"},{"location":"fundamentals/what-is-data/#the-solution-dbt","title":"The Solution: dbt","text":"<pre><code>-- models/staging/stg_orders.sql\nwith source as (\n    select * from {{ source('raw', 'orders') }}\n),\n\ncleaned as (\n    select\n        order_id,\n        customer_id,\n        -- Standardize date format\n        cast(order_date as date) as order_date,\n        -- Convert to USD\n        unit_price * exchange_rate as price_usd,\n        -- Clean up nulls\n        coalesce(shipping_state, 'UNKNOWN') as shipping_state\n    from source\n    where order_id is not null  -- Remove invalid records\n)\n\nselect * from cleaned\n</code></pre> <p>Role: Analytics Engineer</p> <p>Analytics Engineers own the transformation layer, turning messy raw data into clean, analysis-ready tables.</p>"},{"location":"fundamentals/what-is-data/#try-it-yourself","title":"Try It Yourself","text":"<p>Hands-On Exercise</p> <p>Challenge: Identify data quality issues in this sample:</p> <pre><code>    order_id,customer,price,date\n    001,John Smith,25.99,2024-11-07\n    002,John Smith,$26,11/07/2024\n    003,,,-10\n    003,J. Smith,30,2024-11-07\n</code></pre> <pre><code>??? success \"Solution\"\n    Issues found:\n\n    1. Row 2: Inconsistent customer name (same person?)\n    2. Row 2: Price has $ symbol (should be numeric)\n    3. Row 2: Date format differs (MM/DD/YYYY vs YYYY-MM-DD)\n    4. Row 3: Missing customer and price\n    5. Row 3: Negative price (invalid)\n    6. Row 3 &amp; 4: Duplicate order_id\n\n    An Analytics Engineer would write transformations to handle all of these!\n</code></pre>"},{"location":"fundamentals/what-is-data/#whats-next","title":"What's Next?","text":"<p>Now that you understand how data is generated and processed, let's explore the complete Data Lifecycle \u2192</p>"},{"location":"fundamentals/what-is-data/#additional-resources","title":"Additional Resources","text":"<ul> <li>\ud83d\udcfa Video: Data Generation in Action</li> <li>\ud83d\udcc4 Reading: Event-Driven Architecture</li> <li>\ud83d\udcbb GitHub: Sample Event Data</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the Data Roles Guide!</p> <p>This section will help you:</p> <ul> <li>Understand what this guide offers</li> <li>Determine if it's right for you</li> <li>Set up your development environment</li> </ul> <p>Continue to Introduction \u2192</p>"},{"location":"getting-started/introduction/","title":"Introduction","text":"<p>Content coming soon...</p> <p>Next: Who This Is For \u2192</p>"},{"location":"getting-started/setup/","title":"Setup Guide","text":"<p>Content coming soon...</p> <p>Next: What is Data? \u2192</p>"},{"location":"getting-started/who-this-is-for/","title":"Who This Is For","text":"<p>Content coming soon...</p> <p>Next: Setup Guide \u2192</p>"},{"location":"hands-on/","title":"Hands-On Projects","text":"<p>Build real data projects:</p> <ol> <li>Environment Setup</li> <li>Backend API</li> <li>Database Setup</li> <li>Data Pipeline</li> <li>dbt Transformation</li> <li>SQL Analysis</li> <li>Dashboard</li> <li>ML Models</li> <li>Deployment</li> <li>Monitoring</li> </ol>"},{"location":"hands-on/project-overview/","title":"Project Overview: BookStore Analytics","text":"<p>Content coming soon...</p>"},{"location":"reference/","title":"Reference","text":"<p>Quick reference materials:</p> <ul> <li>Glossary</li> <li>Tools Guide</li> <li>Skills Matrix</li> <li>FAQ</li> <li>Tags</li> </ul>"},{"location":"reference/faq/","title":"Frequently Asked Questions","text":"<p>Content coming soon...</p>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>Content coming soon...</p>"},{"location":"reference/skills-matrix/","title":"Skills Matrix","text":"<p>Content coming soon...</p>"},{"location":"reference/tags/","title":"Tags","text":"<p>Browse content by tags.</p>"},{"location":"reference/tools-guide/","title":"Tools Guide","text":"<p>Content coming soon...</p>"},{"location":"roles/","title":"The 20 Data Roles","text":"<p>Explore all 20 data career paths:</p>"},{"location":"roles/#infrastructure--platform","title":"Infrastructure &amp; Platform","text":"<ul> <li>Backend Engineer</li> <li>Database Administrator</li> <li>Platform Engineer</li> <li>DevOps Engineer</li> </ul>"},{"location":"roles/#data-pipeline","title":"Data Pipeline","text":"<ul> <li>Data Engineer</li> <li>Analytics Engineer</li> <li>DataOps Engineer</li> </ul>"},{"location":"roles/#analysis--intelligence","title":"Analysis &amp; Intelligence","text":"<ul> <li>Data Analyst</li> <li>BI Engineer</li> <li>Data Scientist</li> <li>ML Scientist</li> </ul>"},{"location":"roles/#production","title":"Production","text":"<ul> <li>ML Engineer</li> <li>AI Engineer</li> <li>MLOps Engineer</li> </ul>"},{"location":"roles/#support--quality","title":"Support &amp; Quality","text":"<ul> <li>QA Engineer</li> <li>Data Governance</li> <li>Frontend Engineer</li> </ul>"},{"location":"roles/#strategic","title":"Strategic","text":"<ul> <li>Data Architect</li> <li>Data Product Manager</li> <li>Engineering Manager</li> </ul>"},{"location":"roles/data-engineer/","title":"Data Engineer","text":"<p>In Their Own Words</p> <p>\"I build the highways that data travels on. Without reliable pipelines, analysts can't analyse, scientists can't train models, and dashboards show stale data. I make sure data gets from A to B\u2014on time, every time, at scale.\"</p> <p>\u2014 Senior Data Engineer, Tech Company</p>"},{"location":"roles/data-engineer/#role-overview","title":"Role Overview","text":"Also Known As Data Platform Engineer, ETL Developer, Pipeline Engineer Category Data Pipeline Typical Experience 2-8 years Salary Range (US) $90K - $180K Remote Friendly? \u2b50\u2b50\u2b50\u2b50\u2b50 Very (95%+ of jobs)"},{"location":"roles/data-engineer/#what-do-data-engineers-actually-do","title":"What Do Data Engineers Actually Do?","text":"<p>Data Engineers are the builders of the data world. While Data Analysts answer questions and Data Scientists build models, Data Engineers make sure the data is there to work with\u2014clean, reliable, and up-to-date.</p>"},{"location":"roles/data-engineer/#the-core-responsibilities","title":"The Core Responsibilities","text":"Build Data PipelinesDesign Data ArchitectureOptimise PerformanceMonitor &amp; DebugCollaborate <p>Design and implement systems that move data from sources (databases, APIs, files) to destinations (warehouses, lakes) and transform it along the way.</p> Example: Airflow DAG<pre><code>from airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime, timedelta\n\n# Define the pipeline\ndag = DAG(\n    'daily_orders_pipeline',\n    start_date=datetime(2024, 1, 1),\n    schedule_interval='@daily',  # Run every day at midnight\n    catchup=False\n)\n\ndef extract_orders():\n    \"\"\"Extract orders from PostgreSQL\"\"\"\n    orders = read_from_postgres('orders_table')\n    return orders\n\ndef transform_orders(orders):\n    \"\"\"Clean and enrich order data\"\"\"\n    # Remove duplicates\n    # Handle missing values\n    # Add calculated fields\n    return cleaned_orders\n\ndef load_to_warehouse(orders):\n    \"\"\"Load into Snowflake\"\"\"\n    write_to_snowflake('analytics.orders', orders)\n\n# Chain the tasks\nextract = PythonOperator(task_id='extract', python_callable=extract_orders)\ntransform = PythonOperator(task_id='transform', python_callable=transform_orders)\nload = PythonOperator(task_id='load', python_callable=load_to_warehouse)\n\nextract &gt;&gt; transform &gt;&gt; load\n</code></pre> <p>Decide how data should be structured and stored for optimal performance and usability.</p> <pre><code>graph LR\n    A[Source Systems] --&gt; B[Staging Layer&lt;br/&gt;Raw Data]\n    B --&gt; C[Integration Layer&lt;br/&gt;Combined Data]\n    C --&gt; D[Presentation Layer&lt;br/&gt;Analytics-Ready]\n\n    A1[PostgreSQL] --&gt; B\n    A2[Salesforce API] --&gt; B\n    A3[CSV Files] --&gt; B\n\n    D --&gt; E1[Analysts]\n    D --&gt; E2[Dashboards]\n    D --&gt; E3[ML Models]</code></pre> <p>Make queries faster through partitioning, indexing, and efficient data structures.</p> Before: Slow query (45 seconds)<pre><code>-- Scanning entire table (10B rows)\nSELECT *\nFROM orders\nWHERE order_date = '2024-11-07';\n</code></pre> After: Fast query (0.3 seconds)<pre><code>-- Partitioned by date, only scans 1 day's data\nCREATE TABLE orders (\n    order_id VARCHAR,\n    order_date DATE,\n    amount DECIMAL\n)\nPARTITION BY DATE_TRUNC('day', order_date);\n\n-- Now this is fast!\nSELECT *\nFROM orders\nWHERE order_date = '2024-11-07';\n</code></pre> <p>Ensure pipelines run reliably and fix them when they break (and they will break).</p> Monitoring pipeline health<pre><code>def check_pipeline_health():\n    \"\"\"Alert if pipeline failed or data is stale\"\"\"\n\n    # Check last run time\n    last_run = get_last_successful_run('daily_orders_pipeline')\n    if datetime.now() - last_run &gt; timedelta(hours=25):\n        alert_team(\"Pipeline hasn't run in 25 hours!\")\n\n    # Check data freshness\n    latest_date = query(\"SELECT MAX(order_date) FROM analytics.orders\")\n    if latest_date &lt; datetime.now().date() - timedelta(days=1):\n        alert_team(f\"Orders data is stale! Latest: {latest_date}\")\n\n    # Check row counts\n    today_orders = query(\"SELECT COUNT(*) FROM orders WHERE date = CURRENT_DATE\")\n    avg_orders = query(\"SELECT AVG(daily_count) FROM order_stats\")\n    if today_orders &lt; avg_orders * 0.5:  # Less than 50% of average\n        alert_team(f\"Orders unusually low today: {today_orders} vs avg {avg_orders}\")\n</code></pre> <p>Work with everyone\u2014Analysts need data accessible, Scientists need features ready, BI Engineers need dashboards fed.</p> <p>Daily interactions:</p> <ul> <li>\ud83d\udd35 Data Analysts: \"Can you add customer segments to the orders table?\"</li> <li>\ud83d\udfe2 Data Scientists: \"I need purchase history for the last 2 years in a feature store\"</li> <li>\ud83d\udfe3 BI Engineers: \"The dashboard is slow\u2014can you Optimise this query?\"</li> <li>\ud83d\udd34 Backend Engineers: \"We're launching a new API\u2014can you ingest that data?\"</li> <li>\ud83d\udfe1 Product Managers: \"How long would it take to add TikTok marketing data?\"</li> </ul>"},{"location":"roles/data-engineer/#a-day-in-the-life","title":"A Day in the Life","text":""},{"location":"roles/data-engineer/#morning-900-am---1200-pm","title":"Morning (9:00 AM - 12:00 PM)","text":"<pre><code>09:00 - Check Slack: Pipeline failure alert from last night \u26a0\ufe0f\n        Investigate logs, find API rate limit hit\n        Implement exponential backoff retry logic\n        Redeploy and backfill missing data\n\n10:30 - Standup with data team\n        \"Working on fixing last night's pipeline failure\"\n        \"Will work on new Stripe data integration this afternoon\"\n\n11:00 - Code review: Analytics Engineer wrote new dbt models\n        Check SQL efficiency, suggest adding indexes\n        Approve PR\n\n11:30 - Design session: Planning new customer 360 data model\n        Whiteboard how to combine CRM, support tickets, product usage\n</code></pre>"},{"location":"roles/data-engineer/#afternoon-100-pm---500-pm","title":"Afternoon (1:00 PM - 5:00 PM)","text":"<pre><code>13:00 - Build new pipeline: Ingest Stripe payment data\n        Write Airflow DAG\n        Set up incremental loading (only new records)\n        Add data quality tests\n        Deploy to dev environment\n\n15:00 - Performance optimization request from BI team\n        Their dashboard query times out\n        Add partitioning by date\n        Create aggregate tables for common queries\n        Query now runs in 2 seconds instead of 60\n\n16:00 - Documentation: Update data catalog\n        Document new Stripe tables\n        Add data lineage diagrams\n        Write usage examples\n\n16:30 - Check pipeline monitoring dashboard\n        Everything green \u2713\n        Write up notes for tomorrow's work\n</code></pre>"},{"location":"roles/data-engineer/#weekly-responsibilities","title":"Weekly Responsibilities","text":"<ul> <li>Monday: Sprint planning, prioritize pipeline work</li> <li>Tuesday: 1:1 with manager, career development discussion</li> <li>Wednesday: Architecture review meeting, discuss scaling strategy</li> <li>Thursday: Quarterly planning, evaluate new tools (dbt vs custom scripts)</li> <li>Friday: Learning time, try new Apache Spark features</li> </ul>"},{"location":"roles/data-engineer/#key-skills","title":"Key Skills","text":""},{"location":"roles/data-engineer/#must-have-skills","title":"Must-Have Skills","text":"Skill Why It Matters Proficiency Needed SQL Query, transform, and analyse data \u2b50\u2b50\u2b50\u2b50\u2b50 Expert Python Write pipeline logic, data processing \u2b50\u2b50\u2b50\u2b50 Advanced Data Modeling Design efficient schemas \u2b50\u2b50\u2b50\u2b50 Advanced ETL/ELT Concepts Understand data movement patterns \u2b50\u2b50\u2b50\u2b50 Advanced Version Control (Git) Manage code changes \u2b50\u2b50\u2b50\u2b50 Advanced"},{"location":"roles/data-engineer/#important-skills","title":"Important Skills","text":"Skill Why It Matters Proficiency Needed Airflow/Orchestration Schedule and monitor pipelines \u2b50\u2b50\u2b50\u2b50 Advanced Cloud Platforms (AWS/GCP/Azure) Deploy infrastructure \u2b50\u2b50\u2b50 Intermediate Data Warehouses (Snowflake, BigQuery) Target destination for pipelines \u2b50\u2b50\u2b50 Intermediate Spark/Distributed Computing Process large-scale data \u2b50\u2b50\u2b50 Intermediate Linux/Command Line Troubleshoot and automate \u2b50\u2b50\u2b50 Intermediate"},{"location":"roles/data-engineer/#nice-to-have-skills","title":"Nice-to-Have Skills","text":"<ul> <li>Docker/Kubernetes (containerization)</li> <li>Terraform (infrastructure as code)</li> <li>Kafka/Streaming technologies</li> <li>dbt (transformation tool)</li> <li>Monitoring tools (Datadog, Grafana)</li> </ul>"},{"location":"roles/data-engineer/#tools-youll-use-daily","title":"Tools You'll Use Daily","text":""},{"location":"roles/data-engineer/#orchestration","title":"Orchestration","text":"<ul> <li> <p>Apache Airflow</p> <p>Most popular pipeline orchestration tool</p> <pre><code># Schedule and monitor DAGs\ndag = DAG('my_pipeline', schedule_interval='@daily')\n</code></pre> </li> <li> <p>Prefect / Dagster</p> <p>Modern alternatives to Airflow</p> <p>More Pythonic, better testing</p> </li> </ul>"},{"location":"roles/data-engineer/#data-warehouses","title":"Data Warehouses","text":"<ul> <li> <p>Snowflake</p> <p>Cloud data warehouse</p> <p>Separate storage and compute</p> </li> <li> <p>Google BigQuery</p> <p>Serverless data warehouse</p> <p>Pay per query</p> </li> <li> <p>Amazon Redshift</p> <p>AWS data warehouse</p> <p>PostgreSQL-compatible</p> </li> </ul>"},{"location":"roles/data-engineer/#processing-frameworks","title":"Processing Frameworks","text":"<ul> <li> <p>Apache Spark</p> <p>Distributed data processing</p> <pre><code>df = spark.read.parquet('s3://data')\ndf.filter(df.amount &gt; 100).write.parquet('output')\n</code></pre> </li> <li> <p>Pandas</p> <p>Python data manipulation</p> <p>Great for smaller datasets</p> </li> <li> <p>dbt</p> <p>Transform data in warehouse</p> <p>SQL-based, version controlled</p> </li> </ul>"},{"location":"roles/data-engineer/#cloud-platforms","title":"Cloud Platforms","text":"AWSGoogle CloudAzure <ul> <li>S3: Object storage (data lake)</li> <li>RDS: Managed databases</li> <li>Lambda: Serverless functions</li> <li>Glue: ETL service</li> </ul> <ul> <li>Cloud Storage: Object storage</li> <li>Cloud SQL: Managed databases</li> <li>Cloud Functions: Serverless</li> <li>Dataflow: Stream/batch processing</li> </ul> <ul> <li>Blob Storage: Object storage</li> <li>Azure SQL: Managed databases</li> <li>Azure Functions: Serverless</li> <li>Data Factory: ETL service</li> </ul>"},{"location":"roles/data-engineer/#hands-on-project","title":"Hands-On Project","text":"<p>Build Your First Data Pipeline</p> <p>Objective: Create an Airflow pipeline that loads bookstore orders daily</p> <p>What you'll build:</p> <ol> <li>Extract orders from CSV files</li> <li>Transform: Clean data, handle duplicates</li> <li>Load into Snowflake data warehouse</li> <li>Add data quality tests</li> <li>Set up monitoring and alerts</li> </ol> <p>Time estimate: 2-3 hours</p> <p>Start Building \u2192</p>"},{"location":"roles/data-engineer/#career-path","title":"Career Path","text":""},{"location":"roles/data-engineer/#entry-points","title":"Entry Points","text":"From AnalystFrom Software EngineeringBootcamp/Self-Taught <p>Common path: Many Data Engineers start as Data Analysts</p> <p>Transition steps:</p> <ol> <li>Learn Python (beyond just pandas)</li> <li>Automate your SQL queries with scripts</li> <li>Learn Git for version control</li> <li>Start building small pipelines</li> <li>Study Airflow basics</li> </ol> <p>Timeline: 6-12 months</p> <p>Common path: Backend engineers transition to data</p> <p>What to learn:</p> <ol> <li>SQL (you likely know basic, learn advanced)</li> <li>Data modeling concepts</li> <li>Data warehouses (Snowflake, BigQuery)</li> <li>Airflow or similar orchestration</li> <li>Analytics mindset (understand business questions)</li> </ol> <p>Timeline: 3-6 months</p> <p>Focus on:</p> <ol> <li>SQL (most important!)</li> <li>Python fundamentals</li> <li>Build portfolio projects</li> <li>Learn Airflow, dbt, Snowflake</li> <li>Contribute to open source data projects</li> </ol> <p>Timeline: 6-12 months of focused learning</p>"},{"location":"roles/data-engineer/#progression","title":"Progression","text":"<pre><code>graph LR\n    A[Junior Data Engineer&lt;br/&gt;$70-90K&lt;br/&gt;1-2 years] --&gt; B[Data Engineer&lt;br/&gt;$90-130K&lt;br/&gt;2-4 years]\n    B --&gt; C[Senior Data Engineer&lt;br/&gt;$130-180K&lt;br/&gt;4-8 years]\n    C --&gt; D[Staff Data Engineer&lt;br/&gt;$180-250K&lt;br/&gt;8+ years]\n    C --&gt; E[Engineering Manager&lt;br/&gt;$160-220K&lt;br/&gt;6+ years]\n    C --&gt; F[Data Architect&lt;br/&gt;$170-240K&lt;br/&gt;8+ years]</code></pre>"},{"location":"roles/data-engineer/#when-this-role-fits-you","title":"When This Role Fits You","text":"<p>You'll Love This Role If...</p> <ul> <li>\u2705 You enjoy building systems that run reliably</li> <li>\u2705 You like solving technical puzzles (Why did this pipeline fail?)</li> <li>\u2705 You appreciate seeing direct impact (Analysts can now answer questions they couldn't before)</li> <li>\u2705 You're comfortable with ambiguity (Requirements aren't always clear)</li> <li>\u2705 You like variety (Different problems every day)</li> <li>\u2705 You're detail-oriented (One bug can corrupt all downstream data)</li> </ul> <p>This Might Not Be For You If...</p> <ul> <li>\u274c You want to focus on analysis or insights (that's Data Analyst)</li> <li>\u274c You want to build customer-facing products (that's Software Engineering)</li> <li>\u274c You prefer research over production systems (that's ML Scientist)</li> <li>\u274c You don't like being on-call (pipelines break at 3am sometimes)</li> <li>\u274c You prefer working solo (Data Engineering is very collaborative)</li> </ul>"},{"location":"roles/data-engineer/#common-interview-questions","title":"Common Interview Questions","text":"Technical: How would you design a pipeline to process 10TB of data daily? <p>What they're testing: System design, scalability, understanding of distributed computing</p> <p>Good answer covers:</p> <ul> <li>Partitioning strategy (by date, by customer segment)</li> <li>Incremental vs full refresh</li> <li>Parallelization (process chunks simultaneously)</li> <li>Error handling and retry logic</li> <li>Monitoring and alerting</li> <li>Data quality checks</li> </ul> <p>Example answer:</p> <p>\"I'd partition the data by date and process each day in parallel using Spark. I'd use incremental loading to only process new/changed records. I'd implement checkpointing so if a partition fails, we can retry just that partition. I'd add data quality tests (row counts, null checks, schema validation) and set up alerts if any fail. I'd use a columnar format like Parquet for efficient storage and querying.\"</p> Behavioral: Tell me about a time a pipeline broke in production <p>What they're testing: Incident response, communication, learning from mistakes</p> <p>STAR method:</p> <p>Situation: \"Our daily orders pipeline failed at 2am on Black Friday\u2014our busiest day\"</p> <p>Task: \"I needed to get it working ASAP because BI dashboards showed stale data and executives were checking hourly\"</p> <p>Action: \"I checked logs, found API rate limiting was the issue. I implemented exponential backoff and increased our API tier. I backfilled missing data and added better error handling. I also set up better monitoring to catch this earlier next time\"</p> <p>Result: \"Pipeline recovered by 6am. I documented the incident and presented learnings to the team. We now have rate limit monitoring and automatic retry logic\"</p> SQL: Write a query to find duplicate orders <pre><code>-- Find orders that appear more than once\nSELECT \n    order_id,\n    COUNT(*) as duplicate_count\nFROM orders\nGROUP BY order_id\nHAVING COUNT(*) &gt; 1\nORDER BY duplicate_count DESC;\n\n-- Or get the full duplicate records\nWITH duplicates AS (\n    SELECT \n        order_id,\n        ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY created_at DESC) as rn\n    FROM orders\n)\nSELECT *\nFROM orders\nWHERE order_id IN (\n    SELECT order_id FROM duplicates WHERE rn &gt; 1\n);\n</code></pre>"},{"location":"roles/data-engineer/#learning-resources","title":"Learning Resources","text":""},{"location":"roles/data-engineer/#courses","title":"Courses","text":"<ul> <li> DataCamp: Data Engineering Track - Comprehensive, hands-on</li> <li> Udacity: Data Engineering Nanodegree - Project-based</li> <li> Seattle Data Guy YouTube - Free, practical</li> </ul>"},{"location":"roles/data-engineer/#books","title":"Books","text":"<ul> <li>\ud83d\udcda \"Fundamentals of Data Engineering\" by Joe Reis &amp; Matt Housley - Modern best practices</li> <li>\ud83d\udcda \"Designing Data-Intensive Applications\" by Martin Kleppmann - Deep technical foundations</li> <li>\ud83d\udcda \"The Data Warehouse Toolkit\" by Ralph Kimball - Data modeling classic</li> </ul>"},{"location":"roles/data-engineer/#hands-on-practice","title":"Hands-On Practice","text":"<ul> <li>Our BookStore Project - Build a complete pipeline</li> <li>Apache Airflow Tutorial - Official docs</li> <li>dbt Learn - Free transformation course</li> </ul>"},{"location":"roles/data-engineer/#communities","title":"Communities","text":"<ul> <li> dbt Community Slack - 50K+ data practitioners</li> <li> r/dataengineering - Active discussions</li> <li> Data Engineering LinkedIn Groups - Job postings and networking</li> </ul>"},{"location":"roles/data-engineer/#related-roles","title":"Related Roles","text":"Role Overlap Key Difference Analytics Engineer 70% Focus on transformation layer (dbt), less on extraction Data Architect 50% Design systems, less hands-on implementation Backend Engineer 40% Focus on application logic, not data pipelines DataOps Engineer 60% Focus on monitoring and reliability, less on building new pipelines"},{"location":"roles/data-engineer/#next-steps","title":"Next Steps","text":"<p>Ready to try Data Engineering?</p> <p>Build Your First Pipeline \u2192</p> <p>Want to explore more roles?</p> <p>Back to All Roles \u2192</p>"},{"location":"roles/analysis/","title":"analysis Roles","text":"<p>Content coming soon...</p>"},{"location":"roles/data-pipeline/","title":"data pipeline Roles","text":"<p>Content coming soon...</p>"},{"location":"roles/data-pipeline/analytics-engineer/","title":"Analytics Engineer","text":"<p>Content coming soon...</p>"},{"location":"roles/infrastructure/","title":"infrastructure Roles","text":"<p>Content coming soon...</p>"},{"location":"roles/infrastructure/backend-engineer/","title":"Backend Engineer","text":"<p>Content coming soon...</p>"},{"location":"roles/production/","title":"production Roles","text":"<p>Content coming soon...</p>"},{"location":"roles/strategic/","title":"strategic Roles","text":"<p>Content coming soon...</p>"},{"location":"roles/support/","title":"support Roles","text":"<p>Content coming soon...</p>"},{"location":"scenarios/","title":"Real-World Scenarios","text":"<p>See how data roles collaborate:</p> <ul> <li>End-to-End Project</li> <li>Day in the Life</li> <li>Team Collaboration</li> </ul>"},{"location":"scenarios/collaboration/","title":"Team Collaboration","text":"<p>Content coming soon...</p>"},{"location":"scenarios/day-in-the-life/","title":"A Day in the Life","text":"<p>Content coming soon...</p>"},{"location":"scenarios/end-to-end-project/","title":"End-to-End Project","text":"<p>Content coming soon...</p>"}]}